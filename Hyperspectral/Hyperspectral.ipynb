{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6924\n",
      "(2310, 200)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as scio\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spectral\n",
    "\n",
    "#打开mat文件\n",
    "\n",
    "data2 = scio.loadmat('class9-train/data2_train.mat')\n",
    "\n",
    "data3 = scio.loadmat('class9-train/data3_train.mat')\n",
    "\n",
    "data5 = scio.loadmat('class9-train/data5_train.mat')\n",
    "\n",
    "data6 = scio.loadmat('class9-train/data6_train.mat')\n",
    "\n",
    "data8 = scio.loadmat('class9-train/data8_train.mat')\n",
    "\n",
    "data10 = scio.loadmat('class9-train/data10_train.mat')\n",
    "\n",
    "data11 = scio.loadmat('class9-train/data11_train.mat')\n",
    "\n",
    "data12 = scio.loadmat('class9-train/data12_train.mat')\n",
    "\n",
    "data14 = scio.loadmat('class9-train/data14_train.mat')\n",
    "\n",
    "data_test=scio.loadmat('class9-train/data_test_final.mat')\n",
    "\n",
    "#获取数据集\n",
    "\n",
    "data_train2=data2['data2_train']\n",
    "\n",
    "data_train3=data3['data3_train']\n",
    "\n",
    "data_train5=data5['data5_train']\n",
    "\n",
    "data_train6=data6['data6_train']\n",
    "\n",
    "data_train8=data8['data8_train']\n",
    "\n",
    "data_train10=data10['data10_train']\n",
    "\n",
    "data_train11=data11['data11_train']\n",
    "\n",
    "data_train12=data12['data12_train']\n",
    "\n",
    "data_train14=data14['data14_train']\n",
    "\n",
    "#每个类别样本的个数\n",
    "\n",
    "#print(data_train2.shape)(1071, 200)\n",
    "#print(data_train3.shape)(622, 200)\n",
    "#print(data_train5.shape)(362, 200)\n",
    "#print(data_train6.shape)(547, 200)\n",
    "#print(data_train8.shape)(358, 200)\n",
    "#print(data_train10.shape)(729, 200)\n",
    "#print(data_train11.shape)(1841, 200)\n",
    "#print(data_train12.shape)(445, 200)\n",
    "#print(data_train14.shape)(949, 200)\n",
    "print(1071+622+362+547+358+729+1841+445+949)\n",
    "print(data_test['data_test_final'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spectral\n",
    "\n",
    "x_shape=[1071,622,362,547,358,729,1841,445,949]\n",
    "\n",
    "label = [2,3,5,6,8,10,11,12,14]\n",
    "\n",
    "#创建数据集和类别标签合并九个类别为一个数据集\n",
    "\n",
    "data=sio.loadmat('class9-train/data2_train.mat')#返回值是字典\n",
    "\n",
    "key = 'data'+str(2)+'_train'\n",
    "\n",
    "x=data[key]#(6924, 200)\n",
    "\n",
    "y=np.ones(6924)\n",
    "\n",
    "sum=0\n",
    "\n",
    "for m in range(9):\n",
    "    \n",
    "    for n in range(sum,sum+x_shape[m]):\n",
    "        \n",
    "        y[n]=label[m]\n",
    "        \n",
    "    sum=sum+x_shape[m]\n",
    "    \n",
    "#547,358,729,1841,445,949\n",
    "#print(train_y[1071+622+362+547+358+729+1841+445+949-1])\n",
    "\n",
    "for i in range(1,9):\n",
    "    \n",
    "    data = sio.loadmat('class9-train/data'+str(label[i])+'_train.mat')\n",
    "    \n",
    "    key = 'data'+str(label[i])+'_train'\n",
    "    \n",
    "    x=np.append(x,data[key],axis=0)\n",
    "    \n",
    "#print(x.shape)#(6924, 200)\n",
    "#print(y.shape)#(6924,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangju/test/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/wangju/test/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/wangju/test/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.9052570768342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train_model.m']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#标准化数据：将数据按期属性（按列进行）减去其均值，并处以其方差。得到的结果是，\n",
    "#对于每个属性/每列来说所有数据都聚集在0附近，方差为1\n",
    "\n",
    "data_D=preprocessing.StandardScaler().fit_transform(x)\n",
    "\n",
    "data_L=y\n",
    "\n",
    "#data_D.shape(6924, 200)\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(data_D,data_L,test_size=0.5)\n",
    "\n",
    "# 模型训练与拟合 \n",
    "\n",
    "clf = SVC(kernel='rbf',gamma=0.125,C=15) \n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份\n",
    "\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid)\n",
    "\n",
    "grid.fit(data_train,label_train) \n",
    "\n",
    "pred = grid.predict(data_test) \n",
    "\n",
    "accuracy = metrics.accuracy_score(label_test, pred)*100 \n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "# 存储结果学习模型，方便之后的调用\n",
    "\n",
    "joblib.dump(grid,'train_model.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "import scipy.io as scio\n",
    "\n",
    "data_test_final=scio.loadmat('class9-train/data_test_final.mat')\n",
    "\n",
    "data_test=data_test_final['data_test_final']\n",
    "\n",
    "clf = joblib.load(\"train_model.m\")\n",
    "\n",
    "predict_label = clf.predict(data_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
