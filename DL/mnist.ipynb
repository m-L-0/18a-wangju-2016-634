{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 下载MNIST数据集并生成DataSet对象\n",
    "# 使用OneHot编码处理标记\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集图片矩阵，代表55000张图片，每张图片为一个向量，其长度为784\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集标记矩阵，代表55000张图片的标记，每张图片为一个10维的独热编码向量\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13949e908>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化训练集中的图片\n",
    "plt.imshow(Image.fromarray(mnist.train.images[0].reshape(28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0, loss 14.0052, acc 0.1087\n",
      "step   500, loss 10.6275, acc 0.3527\n",
      "step  1000, loss 7.5889, acc 0.4186\n",
      "step  1500, loss 6.9451, acc 0.5102\n",
      "step  2000, loss 7.2876, acc 0.5676\n",
      "step  2500, loss 5.0457, acc 0.5945\n",
      "step  3000, loss 6.0507, acc 0.6245\n",
      "step  3500, loss 6.0495, acc 0.6843\n",
      "step  4000, loss 4.6930, acc 0.7200\n",
      "step  4500, loss 3.9358, acc 0.7404\n",
      "step  5000, loss 3.5523, acc 0.7488\n",
      "step  5500, loss 3.5896, acc 0.7603\n",
      "step  6000, loss 4.0652, acc 0.7646\n",
      "step  6500, loss 3.0222, acc 0.7744\n",
      "step  7000, loss 4.5414, acc 0.7748\n",
      "step  7500, loss 3.5276, acc 0.7793\n",
      "step  8000, loss 3.0332, acc 0.7824\n",
      "step  8500, loss 5.2548, acc 0.7805\n",
      "step  9000, loss 2.6073, acc 0.7899\n",
      "step  9500, loss 2.0148, acc 0.7873\n",
      "step 10000, loss 3.8695, acc 0.7896\n",
      "step 10500, loss 2.7537, acc 0.7932\n",
      "step 11000, loss 3.0344, acc 0.7970\n",
      "step 11500, loss 3.0037, acc 0.7941\n",
      "step 12000, loss 1.0237, acc 0.7932\n",
      "step 12500, loss 2.3657, acc 0.8038\n",
      "step 13000, loss 5.0561, acc 0.7970\n",
      "step 13500, loss 2.5188, acc 0.7992\n",
      "step 14000, loss 3.5310, acc 0.8052\n",
      "step 14500, loss 3.0709, acc 0.8036\n",
      "step 15000, loss 2.0149, acc 0.8020\n",
      "step 15500, loss 0.5037, acc 0.8097\n",
      "step 16000, loss 4.5413, acc 0.8041\n",
      "step 16500, loss 1.3762, acc 0.8308\n",
      "step 17000, loss 0.6190, acc 0.8754\n",
      "step 17500, loss 0.2320, acc 0.8788\n",
      "step 18000, loss 2.5101, acc 0.8899\n",
      "step 18500, loss 0.5104, acc 0.8896\n",
      "step 19000, loss 1.9250, acc 0.8916\n",
      "step 19500, loss 1.6071, acc 0.8943\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    # 输入、标记占位符\n",
    "    inputs = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "    labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    # 创建128个隐藏层神经元参数\n",
    "    hidden_weight = tf.Variable(tf.random_normal([784, 128]), name='hidden_weight')\n",
    "    hidden_bias = tf.Variable(tf.zeros([128, ]), name='hidden_bias')\n",
    "    # 隐藏层前向传播\n",
    "    hidden_output = tf.nn.relu(tf.matmul(inputs, hidden_weight) + hidden_bias)\n",
    "    \n",
    "    \n",
    "    # 创建输出层10个神经元参数\n",
    "    output_weight = tf.Variable(tf.random_normal([128, 10], name='output_weight'))\n",
    "    output_bias = tf.Variable(tf.zeros([10, ]), name='output_bias')\n",
    "    # 输出层前向传播\n",
    "    logits = tf.matmul(hidden_output, output_weight) + output_bias\n",
    "    output = tf.nn.softmax(logits)\n",
    "    \n",
    "    \n",
    "    # 代价函数\n",
    "    loss = tf.reduce_mean(-1 * tf.reduce_sum(\n",
    "        labels * tf.log(output + 1e-7),\n",
    "        axis=1))\n",
    "    \n",
    "    \n",
    "    # 正确率\n",
    "    acc = tf.reduce_mean(\n",
    "        tf.cast(tf.equal(tf.argmax(labels, axis=1), tf.argmax(output, axis=1)),\n",
    "                tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # 定义梯度下降法优化器\n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    train_op = optim.minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 训练模型\n",
    "    for step in range(20000):\n",
    "        batch_images, batch_labels = mnist.train.next_batch(32)\n",
    "        res_loss, _ = sess.run([loss, train_op], feed_dict={\n",
    "            inputs: batch_images,\n",
    "            labels: batch_labels\n",
    "        })\n",
    "        \n",
    "        # 输出代价并验证模型\n",
    "        if step % 500 == 0:\n",
    "            accs = []\n",
    "            for test_step in range(10000 // 32):\n",
    "                batch_images, batch_labels = mnist.test.next_batch(32)\n",
    "                res_acc = sess.run(acc, feed_dict={\n",
    "                    inputs: batch_images,\n",
    "                    labels: batch_labels\n",
    "                })\n",
    "                accs.append(res_acc)\n",
    "            accs = np.mean(accs)\n",
    "            print('step %5d, loss %2.4f, acc %.4f' % (step, res_loss, accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
